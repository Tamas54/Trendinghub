"""
Google AI Generator for TrendMaster
Uses Gemini 3, Nano Banana Pro (Gemini 3 Pro Image), and Veo 3.1 (Video) APIs
"""
import google.generativeai as genai
from google import genai as genai_new  # New SDK for image and video generation
from google.genai import types as genai_types
import os
from typing import List, Dict, Optional
from dotenv import load_dotenv
import time

# Load environment variables
load_dotenv()


class GoogleAIGenerator:
    def __init__(self):
        """Initialize Google AI client"""
        api_key = os.getenv('GOOGLE_API_KEY')

        if not api_key:
            print("‚ö†Ô∏è GOOGLE_API_KEY not found in environment")
            self.client = None
            self.new_client = None
        else:
            try:
                genai.configure(api_key=api_key)

                # Initialize models
                self.text_model_name = os.getenv('GEMINI_TEXT_MODEL', 'gemini-3-pro-preview')
                self.image_model_name = os.getenv('GEMINI_IMAGE_MODEL', 'gemini-3-pro-image-preview')
                self.video_model_name = os.getenv('GEMINI_VIDEO_MODEL', 'veo-3.1-generate-preview')

                # Test connection with Gemini 3 (old API for text)
                self.text_model = genai.GenerativeModel(self.text_model_name)

                # Initialize new client for image/video (Nano Banana, Veo)
                self.new_client = genai_new.Client(api_key=api_key)

                print("‚úÖ Google AI API initialized")
                print(f"   ‚Ä¢ Text: {self.text_model_name}")
                print(f"   ‚Ä¢ Image: {self.image_model_name} (Nano Banana)")
                print(f"   ‚Ä¢ Video: {self.video_model_name}")
            except Exception as e:
                print(f"‚ùå Google AI initialization failed: {e}")
                self.client = None
                self.new_client = None

    def generate_facebook_posts(self, trend_topic: str, source: str, metadata: str = "") -> List[str]:
        """
        Generate 3 Facebook post variations using Gemini 3

        Args:
            trend_topic: The trending topic
            source: Source of the trend
            metadata: Additional context

        Returns:
            List of 3 generated Facebook posts
        """
        if not hasattr(self, 'text_model'):
            return [
                f"‚ùå Google AI nem el√©rhet≈ë\n\nT√©ma: {trend_topic}",
                f"‚ùå Google AI nem el√©rhet≈ë\n\nT√©ma: {trend_topic}",
                f"‚ùå Google AI nem el√©rhet≈ë\n\nT√©ma: {trend_topic}"
            ]

        prompt = f"""
        K√©sz√≠ts 3 k√ºl√∂nb√∂z≈ë Facebook posztot a k√∂vetkez≈ë trending t√©m√°r√≥l.

        T√âMA: {trend_topic}
        FORR√ÅS: {source}
        EXTRA INFO: {metadata}

        ‚ö†Ô∏è FONTOS: A posztokat MINDIG MAGYAR NYELVEN √≠rd, m√©g akkor is, ha a t√©ma angol nyelv≈±!
        Ha a t√©ma angol, ford√≠tsd le a tartalmat magyarra, de √∫gy, hogy √©rthet≈ë √©s term√©szetes legyen.

        K√ñVETELM√âNYEK (K√ñTELEZ≈ê):

        1. **C√âLK√ñZ√ñNS√âG**: Korm√°nybiztosnak sz√°nt tartalom
           - Professzion√°lis, de bar√°ts√°gos hangnem
           - Humoros, de m√©lt√≥s√°gteljes
           - Informat√≠v √©s l√©nyegre t√∂r≈ë
           - Szakmai hiteless√©get sugall

        2. **FACEBOOK ALGORITMUS BAR√ÅT ELEMEK**:
           - Haszn√°lj 2-3 j√≥l megv√°lasztott emojit (nem t√∫l sok!)
           - Alkalmazz **vastag bet≈±s** kiemel√©seket a l√©nyeges pontokn√°l
           - Haszn√°lj k√ºl√∂nleges karaktereket m√©rt√©kkel (‚úì, ‚Üí, ‚Ä¢)
           - K√©rd√©seket vagy felki√°lt√°sokat a bevonz√°s√©rt

        3. **SZERKEZET**:
           - Figyelemfelkelt≈ë els≈ë mondat (hook)
           - 3-4 informat√≠v mondatban r√©szletesen fejtsd ki a t√©m√°t
           - Kontextus: mi√©rt fontos ez most, milyen hat√°sai vannak
           - √ârzelmi kapcsol√≥d√°si pont vagy perspekt√≠va
           - Gondolat√©breszt≈ë lez√°r√°s vagy k√©rd√©s

        4. **HOSSZ √âS ST√çLUS**:
           - 200-350 karakter √∂sszesen (r√©szletesebb, informat√≠vabb)
           - J√≥l struktur√°lt, koherens mondatok
           - K√∂nnyen olvashat√≥, de tartalmas
           - H√∫z√≥nevek/kulcsszavak kiemel√©se
           - Relev√°ns r√©szletek, adatok, √∂sszef√ºgg√©sek bemutat√°sa

        5. **POLITIKAI TARTALOM**: MEGENGEDETT
           - Objekt√≠v, t√©nyszer≈± megk√∂zel√≠t√©s
           - Kiegyens√∫lyozott √°ll√°spont
           - T√∂bb n√©z≈ëpont bemutat√°sa

        6. **H√ÅROM K√úL√ñNB√ñZ≈ê ST√çLUS**:
           - **1. poszt**: Informat√≠v, profi, t√©nyk√∂zpont√∫
           - **2. poszt**: Humoros, k√∂z√©rthet≈ë, relatable
           - **3. poszt**: Gondolat√©breszt≈ë, elemz≈ë, strat√©giai

        FONTOS:
        - NE haszn√°lj hashtag-eket (#)
        - NE √≠rj link placeholder-eket
        - NE haszn√°lj t√∫l sok emojit (max 3 √∂sszesen)
        - NE legy√©l t√∫l form√°lis vagy unalmas

        V√ÅLASZ FORM√ÅTUM (PONTOSAN √çGY):
        ---POST1---
        [els≈ë poszt sz√∂vege]
        ---POST2---
        [m√°sodik poszt sz√∂vege]
        ---POST3---
        [harmadik poszt sz√∂vege]
        """

        try:
            response = self.text_model.generate_content(
                prompt,
                generation_config={
                    'temperature': 0.8,
                    'max_output_tokens': 800,
                }
            )

            # Parse response
            response_text = response.text.strip()

            # Extract posts
            posts = []
            parts = response_text.split('---POST')

            for part in parts[1:]:  # Skip first empty part
                # Extract content between --- markers
                content = part.split('---')[1].strip() if '---' in part else part.strip()

                # Clean up post
                content = content.replace('POST1', '').replace('POST2', '').replace('POST3', '')
                content = content.strip()

                if content:
                    posts.append(content)

            # Ensure we have exactly 3 posts
            while len(posts) < 3:
                posts.append(f"üì¢ {trend_topic}\n\nEz a t√©ma most felkapott! Mit gondolsz r√≥la?")

            print(f"‚úÖ Generated {len(posts)} Facebook posts for: {trend_topic[:50]}... (via Gemini 3)")

            return posts[:3]

        except Exception as e:
            print(f"‚ùå Error generating posts with Gemini 3: {e}")
            # Fallback posts
            return [
                f"üìä **{trend_topic}**\n\nEz a t√©ma most a figyelem k√∂z√©ppontj√°ban! √ârdemes figyelni.",
                f"üî• {trend_topic}\n\nAz emberek ezt keresik most! Mit gondolsz, mi√©rt lehet ennyire aktu√°lis?",
                f"üí° **Trending most**: {trend_topic}\n\n√ârdekes k√©rd√©s, hogy ez hogyan hat a j√∂v≈ëre."
            ]

    def generate_text(self, prompt: str) -> str:
        """
        Generate text using Gemini 3 (generic text generation)

        Args:
            prompt: The prompt to generate text from

        Returns:
            Generated text string
        """
        if not hasattr(self, 'text_model'):
            return "‚ùå Google AI nem el√©rhet≈ë"

        try:
            print(f"üìù Generating text with Gemini 3: {prompt[:50]}...")

            response = self.text_model.generate_content(prompt)

            if response and response.text:
                return response.text.strip()
            else:
                return "‚ùå Nem siker√ºlt sz√∂veget gener√°lni"

        except Exception as e:
            print(f"‚ùå Error generating text with Gemini 3: {e}")
            return f"‚ùå Hiba a sz√∂veg gener√°l√°s sor√°n: {str(e)}"

    def generate_image(self, prompt: str) -> str:
        """
        Generate an image using Nano Banana Pro (Gemini 3 Pro Image)
        Uses the new google.genai SDK with response_modalities=['TEXT', 'IMAGE']

        Args:
            prompt: Text description for image generation

        Returns:
            Path to the generated image file (to be served via Flask)
        """
        if not self.new_client:
            print("‚ö†Ô∏è Google AI new client not available, using fallback")
            return "https://images.unsplash.com/photo-1557683316-973673baf926?auto=format&fit=crop&w=1000"

        try:
            print(f"üé® Generating image with Nano Banana (Gemini 3 Pro Image): {prompt[:50]}...")

            import tempfile
            import uuid

            # Clean the prompt for safety filters
            import re
            emoji_pattern = re.compile("["
                u"\U0001F600-\U0001F64F"
                u"\U0001F300-\U0001F5FF"
                u"\U0001F680-\U0001F6FF"
                u"\U0001F1E0-\U0001F1FF"
                u"\U00002702-\U000027B0"
                u"\U000024C2-\U0001F251"
                "]+", flags=re.UNICODE)
            clean_prompt = emoji_pattern.sub('', prompt)
            clean_prompt = re.sub(r'\*\*|\*|__|_|`|#', '', clean_prompt)
            clean_prompt = re.sub(r'[<>{}[\]|\\^~]', '', clean_prompt).strip()

            full_prompt = f"Create a professional, cinematic image: {clean_prompt}. High quality, photorealistic style."

            # Use new SDK for image generation
            response = self.new_client.models.generate_content(
                model=self.image_model_name,  # "gemini-3-pro-image-preview"
                contents=[full_prompt],
                config=genai_types.GenerateContentConfig(
                    response_modalities=['TEXT', 'IMAGE'],
                    image_config=genai_types.ImageConfig(
                        aspect_ratio="1:1",
                        image_size="2K"
                    ),
                )
            )

            # Extract and save image from response
            temp_dir = tempfile.gettempdir()
            temp_filename = f"nano_banana_{uuid.uuid4()}.png"
            temp_path = os.path.join(temp_dir, temp_filename)

            for part in response.parts:
                if part.text is not None:
                    print(f"   Gemini: {part.text[:100]}...")
                elif image := part.as_image():
                    image.save(temp_path)
                    print(f"‚úÖ Image generated successfully with Nano Banana")
                    return temp_path

            raise ValueError("No image generated in response")

        except Exception as e:
            print(f"‚ùå Nano Banana image generation failed: {e}")
            import traceback
            traceback.print_exc()
            # Fallback image
            return "https://images.unsplash.com/photo-1557683316-973673baf926?auto=format&fit=crop&w=1000"

    def generate_video(self, prompt: str, duration: int = 5) -> str:
        """
        Generate a video using Veo 3.1

        Args:
            prompt: Text description for video generation
            duration: Video duration in seconds (4, 6, or 8)

        Returns:
            Path to the generated video file
        """
        try:
            import tempfile
            import uuid

            print(f"üé¨ Generating video with Veo 3.1: {prompt[:50]}...")

            # Map duration to allowed values (4, 6, 8 seconds)
            allowed_durations = {4: "4", 5: "4", 6: "6", 8: "8"}
            duration_str = str(allowed_durations.get(duration, "4"))
            if duration not in [4, 5, 6, 8]:
                print(f"‚ö†Ô∏è Duration {duration}s not allowed, using 4s instead")

            # Clean prompt: Remove emojis, markdown, and special formatting
            # Veo 3.1 generates audio natively, so clean text works better
            import re
            cleaned_prompt = prompt

            # Remove emojis
            cleaned_prompt = re.sub(r'[^\w\s\.,!?\-√°√©√≠√≥√∂≈ë√∫√º≈±√Å√â√ç√ì√ñ≈ê√ö√ú≈∞]', '', cleaned_prompt)

            # Remove markdown formatting
            cleaned_prompt = re.sub(r'\*\*([^*]+)\*\*', r'\1', cleaned_prompt)  # **bold**
            cleaned_prompt = re.sub(r'\*([^*]+)\*', r'\1', cleaned_prompt)      # *italic*

            # Clean up extra spaces
            cleaned_prompt = ' '.join(cleaned_prompt.split())

            print(f"üßπ Cleaned prompt: {cleaned_prompt[:80]}...")

            # Initialize new GenAI client for Veo
            api_key = os.getenv('GOOGLE_API_KEY')
            client = genai_new.Client(api_key=api_key)

            # Step 1: Create video generation job
            print(f"üì§ Creating Veo 3.1 video job...")
            operation = client.models.generate_videos(
                model=self.video_model_name,  # "veo-3.1-generate-preview"
                prompt=f"Professional social media video: {cleaned_prompt}",
                config=genai_new.types.GenerateVideosConfig(
                    duration_seconds=duration_str,
                    aspect_ratio="16:9",
                    resolution="720p"
                )
            )

            print(f"‚úÖ Video job created: {operation.name}")

            # Step 2: Poll operation status until completed
            max_wait_time = 360  # 6 minutes max
            start_time = time.time()
            poll_interval = 10  # Check every 10 seconds

            while not operation.done:
                if time.time() - start_time > max_wait_time:
                    print(f"‚ùå Video generation timed out after {max_wait_time}s")
                    return None

                print(f"‚è≥ Waiting for video generation to complete...")
                time.sleep(poll_interval)

                # Refresh operation status
                operation = client.operations.get(operation)

            print(f"‚úÖ Video generation completed!")

            # Step 3: Check if video was filtered by safety system
            if hasattr(operation.response, 'rai_media_filtered_count') and operation.response.rai_media_filtered_count and operation.response.rai_media_filtered_count > 0:
                print(f"üö´ Video generation blocked by Veo safety filter!")
                if hasattr(operation.response, 'rai_media_filtered_reasons'):
                    for reason in operation.response.rai_media_filtered_reasons:
                        print(f"   üìã {reason}")
                return None

            # Check if generated_videos exists and is not empty
            if not operation.response or not hasattr(operation.response, 'generated_videos'):
                print(f"‚ùå No generated_videos in response")
                return None

            if not operation.response.generated_videos:
                print(f"‚ùå generated_videos is empty")
                return None

            generated_video = operation.response.generated_videos[0]

            temp_dir = tempfile.gettempdir()
            temp_filename = f"veo3_{uuid.uuid4()}.mp4"
            temp_path = os.path.join(temp_dir, temp_filename)

            print(f"üì• Downloading video...")
            client.files.download(file=generated_video.video)
            generated_video.video.save(temp_path)

            print(f"‚úÖ Video generated successfully with Veo 3.1")
            print(f"   Saved to: {temp_path}")

            return temp_path

        except Exception as e:
            print(f"‚ùå Veo 3.1 video generation failed: {e}")
            import traceback
            traceback.print_exc()
            return None

    def generate_video_prompt_from_post(self, post_text: str) -> str:
        """
        Generate a clean video prompt from Facebook post text

        Args:
            post_text: The Facebook post text

        Returns:
            A clean, simple visual description for Veo 3.1
        """
        if not hasattr(self, 'text_model'):
            return "Egy sz√©p t√°jk√©p napfelkeltekor."

        prompt = f"""
        Alak√≠tsd √°t ezt a Facebook post sz√∂veget egy egyszer≈±, r√∂vid vizu√°lis le√≠r√°ss√° vide√≥ gener√°l√°shoz.

        K√ñVETELM√âNYEK:
        - Maximum 80 karakter
        - Nincs emoji, markdown formatting, speci√°lis karakter
        - Nincs val√≥s szem√©ly neve (politikusok, celebrityek)
        - Egyszer≈±, konkr√©t vizu√°lis jelenet le√≠r√°sa
        - Magyar nyelven
        - Csak egy egyszer≈± mondat vagy k√©t r√∂vid mondat

        P√âLD√ÅK:
        Post: "üî• **Trump b√©keterve** ‚Äì politikai vihar k√∂zeleg!"
        Vide√≥ prompt: "Diplom√°ciai t√°rgyal√°s egy modern irod√°ban, emberek vitatkoznak."

        Post: "√öj gazdas√°gi v√°ls√°g j√∂het! üìä Mit gondolsz?"
        Vide√≥ prompt: "Egy t≈ëzsde keresked√©si terem, monitor grafikonokkal."

        Post: "Gy√∂ny√∂r≈± napfelkelte a hegyekben! üèîÔ∏è‚ú®"
        Vide√≥ prompt: "Napfelkelte a havas hegyek felett, arany f√©ny."

        FACEBOOK POST:
        {post_text}

        V√°lasz CSAK a vide√≥ prompttal, semmi m√°ssal! Ne √≠rj semmilyen magyar√°zatot!
        """

        try:
            response = self.text_model.generate_content(
                prompt,
                generation_config={
                    'temperature': 0.7,
                    'max_output_tokens': 100,
                }
            )

            # Clean response
            video_prompt = response.text.strip()

            # Remove any quotes if present
            video_prompt = video_prompt.strip('"').strip("'")

            # Limit to 80 characters
            if len(video_prompt) > 80:
                video_prompt = video_prompt[:77] + "..."

            print(f"‚úÖ Generated video prompt: {video_prompt}")

            return video_prompt

        except Exception as e:
            print(f"‚ùå Error generating video prompt: {e}")
            return "Egy dinamikus jelenet modern k√∂rnyezetben."

    def generate_posts_batch(self, trends: List[Dict], max_trends: int = 5) -> Dict[int, List[str]]:
        """
        Generate posts for multiple trends using Gemini 3

        Args:
            trends: List of trend dictionaries
            max_trends: Maximum number of trends to process

        Returns:
            Dictionary mapping trend_id to list of posts
        """
        results = {}

        for idx, trend in enumerate(trends[:max_trends]):
            print(f"\nü§ñ Generating posts {idx+1}/{min(len(trends), max_trends)} (Gemini 3)")

            trend_id = trend.get('id')
            topic = trend.get('topic', 'Unknown topic')
            source = trend.get('source', 'unknown')
            metadata = trend.get('metadata', '')

            posts = self.generate_facebook_posts(topic, source, metadata)
            results[trend_id] = posts

            # Rate limiting for Google AI
            time.sleep(1)

        return results
