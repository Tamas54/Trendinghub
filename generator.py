"""
Facebook Post Generator for TrendMaster
Uses OpenAI API to generate engaging Facebook posts
"""
from openai import OpenAI
import os
from typing import List, Dict, Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# GPT-5 models (latest generation)
OPENAI_MODEL = 'gpt-5-mini'  # Primary model for post generation
OPENAI_TEXT_MODEL = 'gpt-5-mini'  # Model for text generation


def get_rag_style_context(topic: str) -> str:
    """
    Get RAG style context for a given topic.
    Returns empty string if RAG store is not available or has no data.
    """
    try:
        from rag_store import get_rag_store
        rag_store = get_rag_store()
        context = rag_store.get_style_context(topic, max_tokens=800)
        if context:
            print(f"üé≠ RAG style context added ({len(context)} chars)")
        return context
    except Exception as e:
        # RAG store not available or error - silently continue without it
        return ""


class PostGenerator:
    def __init__(self):
        """Initialize OpenAI client"""
        api_key = os.getenv('OPENAI_API_KEY')

        if not api_key:
            print("‚ö†Ô∏è OPENAI_API_KEY not found in environment")
            self.client = None
        else:
            try:
                self.client = OpenAI(api_key=api_key)
                print("‚úÖ OpenAI API initialized")
            except Exception as e:
                print(f"‚ùå OpenAI initialization failed: {e}")
                self.client = None

    def generate_facebook_posts(self, trend_topic: str, source: str, metadata: str = "") -> List[str]:
        """
        Generate 3 Facebook post variations for a trend

        Args:
            trend_topic: The trending topic
            source: Source of the trend (e.g., google_hu, youtube_us)
            metadata: Additional context about the trend

        Returns:
            List of 3 generated Facebook posts
        """
        if not self.client:
            return [
                f"‚ùå OpenAI API nem el√©rhet≈ë\n\nT√©ma: {trend_topic}",
                f"‚ùå OpenAI API nem el√©rhet≈ë\n\nT√©ma: {trend_topic}",
                f"‚ùå OpenAI API nem el√©rhet≈ë\n\nT√©ma: {trend_topic}"
            ]

        # ALWAYS generate in Hungarian (for Hungarian government official)
        language = "magyar"

        # Get RAG style context if available
        rag_context = get_rag_style_context(trend_topic)

        prompt = f"""
        K√©sz√≠ts 3 k√ºl√∂nb√∂z≈ë Facebook posztot a k√∂vetkez≈ë trending t√©m√°r√≥l.

        T√âMA: {trend_topic}
        FORR√ÅS: {source}

        R√âSZLETES TARTALOM (HASZN√ÅLD EZT A POSZT MEG√çR√ÅS√ÅHOZ!):
        {metadata}

        {rag_context}

        ‚ö†Ô∏è K√ñTELEZ≈ê: Haszn√°ld fel a fenti R√âSZLETES TARTALOM inform√°ci√≥it a poszt meg√≠r√°s√°hoz! Ne csak a c√≠mre hagyatkozz!

        ‚ö†Ô∏è FONTOS: A posztokat MINDIG MAGYAR NYELVEN √≠rd, m√©g akkor is, ha a t√©ma angol nyelv≈±!
        Ha a t√©ma angol, ford√≠tsd le a tartalmat magyarra, de √∫gy, hogy √©rthet≈ë √©s term√©szetes legyen.

        K√ñVETELM√âNYEK (K√ñTELEZ≈ê):

        1. **C√âLK√ñZ√ñNS√âG**: Korm√°nybiztosnak sz√°nt tartalom
           - Professzion√°lis, de bar√°ts√°gos hangnem
           - Humoros, de m√©lt√≥s√°gteljes
           - Informat√≠v √©s l√©nyegre t√∂r≈ë
           - Szakmai hiteless√©get sugall

        2. **FACEBOOK ALGORITMUS BAR√ÅT ELEMEK**:
           - Haszn√°lj 2-3 j√≥l megv√°lasztott emojit (nem t√∫l sok!)
           - Alkalmazz **vastag bet≈±s** kiemel√©seket a l√©nyeges pontokn√°l
           - Haszn√°lj k√ºl√∂nleges karaktereket m√©rt√©kkel (‚úì, ‚Üí, ‚Ä¢)
           - K√©rd√©seket vagy felki√°lt√°sokat a bevonz√°s√©rt

        3. **SZERKEZET**:
           - Figyelemfelkelt≈ë els≈ë mondat (hook)
           - 3-4 informat√≠v mondatban r√©szletesen fejtsd ki a t√©m√°t
           - Kontextus: mi√©rt fontos ez most, milyen hat√°sai vannak
           - √ârzelmi kapcsol√≥d√°si pont vagy perspekt√≠va
           - Gondolat√©breszt≈ë lez√°r√°s vagy k√©rd√©s

        4. **HOSSZ √âS ST√çLUS**:
           - 500-800 karakter √∂sszesen (r√©szletesebb, informat√≠vabb, tartalmas)
           - J√≥l struktur√°lt, koherens mondatok
           - K√∂nnyen olvashat√≥, de tartalmas
           - H√∫z√≥nevek/kulcsszavak kiemel√©se
           - Relev√°ns r√©szletek, adatok, √∂sszef√ºgg√©sek bemutat√°sa
           - Legyen el√©g hossz√∫ ahhoz, hogy √©rt√©kes inform√°ci√≥t adjon!

        5. **POLITIKAI TARTALOM**: MEGENGEDETT
           - Objekt√≠v, t√©nyszer≈± megk√∂zel√≠t√©s
           - Kiegyens√∫lyozott √°ll√°spont
           - T√∂bb n√©z≈ëpont bemutat√°sa

        6. **H√ÅROM K√úL√ñNB√ñZ≈ê ST√çLUS**:
           - **1. poszt**: Informat√≠v, profi, t√©nyk√∂zpont√∫
           - **2. poszt**: Humoros, k√∂z√©rthet≈ë, relatable
           - **3. poszt**: Gondolat√©breszt≈ë, elemz≈ë, strat√©giai

        FONTOS:
        - NE haszn√°lj hashtag-eket (#)
        - NE √≠rj link placeholder-eket
        - NE haszn√°lj t√∫l sok emojit (max 3 √∂sszesen)
        - NE legy√©l t√∫l form√°lis vagy unalmas

        V√ÅLASZ FORM√ÅTUM (PONTOSAN √çGY):
        ---POST1---
        [els≈ë poszt sz√∂vege]
        ---POST2---
        [m√°sodik poszt sz√∂vege]
        ---POST3---
        [harmadik poszt sz√∂vege]
        """

        try:
            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,  # GPT-5 mini - latest generation
                messages=[
                    {
                        "role": "system",
                        "content": """Te egy szak√©rt≈ë k√∂z√∂ss√©gi m√©dia menedzser vagy, aki korm√°nybiztosok sz√°m√°ra k√©sz√≠t professzion√°lis, de engaging Facebook posztokat.

FONTOS K√ñVETELM√âNYEK:
‚Ä¢ √ârted a Facebook ALGORITMUS√ÅT √©s tudod, hogyan kell olyan tartalmat k√©sz√≠teni, ami tetszik mind az ALGORITMUSNAK, mind a K√ñZ√ñNS√âGNEK
‚Ä¢ Haszn√°lj T√ñBB EMOJIT, mivel ez Facebook poszt - az emojik n√∂velik az engagement-et
‚Ä¢ A poszt szakmailag hiteles maradjon, de legyen √©rdekes √©s figyelemfelkelt≈ë
‚Ä¢ MINDEN posztot K√ñTELEZ≈êEN ezzel a mondattal fejezd be: "link a kommentben"

ST√çLUS: Professzion√°lis, de bar√°ts√°gos √©s engaging. Emojikkal fokozd a figyelmet √©s az olvashat√≥s√°got."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                # GPT-5-mini only supports default temperature (1), don't set it
                max_completion_tokens=2000  # Enough for 3 detailed posts of 500-800 chars each
            )

            # Parse response
            response_text = response.choices[0].message.content.strip()

            # Extract posts
            posts = []
            parts = response_text.split('---POST')

            for part in parts[1:]:  # Skip first empty part
                # Extract content between --- markers
                content = part.split('---')[1].strip() if '---' in part else part.strip()

                # Clean up post
                content = content.replace('POST1', '').replace('POST2', '').replace('POST3', '')
                content = content.strip()

                if content:
                    posts.append(content)

            # Ensure we have exactly 3 posts
            while len(posts) < 3:
                posts.append(f"üì¢ {trend_topic}\n\nEz a t√©ma most felkapott! Mit gondolsz r√≥la?")

            print(f"‚úÖ Generated {len(posts)} Facebook posts for: {trend_topic[:50]}...")

            return posts[:3]

        except Exception as e:
            print(f"‚ùå Error generating posts: {e}")
            # Fallback posts
            return [
                f"üìä **{trend_topic}**\n\nEz a t√©ma most a figyelem k√∂z√©ppontj√°ban! √ârdemes figyelni.",
                f"üî• {trend_topic}\n\nAz emberek ezt keresik most! Mit gondolsz, mi√©rt lehet ennyire aktu√°lis?",
                f"üí° **Trending most**: {trend_topic}\n\n√ârdekes k√©rd√©s, hogy ez hogyan hat a j√∂v≈ëre."
            ]

    def generate_text(self, prompt: str) -> str:
        """
        Generate text using GPT-4 (generic text generation)

        Args:
            prompt: The prompt to generate text from

        Returns:
            Generated text string
        """
        if not self.client:
            return "‚ùå OpenAI API nem el√©rhet≈ë"

        try:
            print(f"üìù Generating text with {OPENAI_TEXT_MODEL}: {prompt[:50]}...")

            response = self.client.chat.completions.create(
                model=OPENAI_TEXT_MODEL,  # GPT-5 mini
                messages=[
                    {"role": "system", "content": "Te egy kreat√≠v tartalom√≠r√≥ vagy, aki social media posztokat √©s vide√≥ scripteket k√©sz√≠t."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=1000  # GPT-5 uses max_completion_tokens, no temperature support
            )

            if response.choices:
                return response.choices[0].message.content.strip()
            else:
                return "‚ùå Nem siker√ºlt sz√∂veget gener√°lni"

        except Exception as e:
            print(f"‚ùå Error generating text with GPT-4: {e}")
            return f"‚ùå Hiba a sz√∂veg gener√°l√°s sor√°n: {str(e)}"

    def generate_posts_batch(self, trends: List[Dict], max_trends: int = 5) -> Dict[int, List[str]]:
        """
        Generate posts for multiple trends

        Args:
            trends: List of trend dictionaries
            max_trends: Maximum number of trends to process

        Returns:
            Dictionary mapping trend_id to list of posts
        """
        results = {}

        for idx, trend in enumerate(trends[:max_trends]):
            print(f"\nü§ñ Generating posts {idx+1}/{min(len(trends), max_trends)}")

            trend_id = trend.get('id')
            topic = trend.get('topic', 'Unknown topic')
            source = trend.get('source', 'unknown')
            metadata = trend.get('metadata', '')

            posts = self.generate_facebook_posts(topic, source, metadata)
            results[trend_id] = posts

        return results

    def generate_image_prompt(self, post_text: str) -> str:
        """
        Generate an optimized image prompt from post text using GPT-5

        Args:
            post_text: The social media post text

        Returns:
            Optimized image prompt for AI image generation
        """
        if not self.client:
            return f"Social media visual for: {post_text[:200]}"

        try:
            print(f"üìù Generating image prompt from post...")

            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": """Te egy AI k√©pgener√°l√≥ prompt szak√©rt≈ë vagy. A feladatod, hogy social media posztokb√≥l k√©sz√≠ts optimaliz√°lt k√©pgener√°l√≥ promptokat.

A prompt legyen:
- Angol nyelv≈± (a legjobb k√©pgener√°torok angolul m≈±k√∂dnek)
- Vizu√°lisan le√≠r√≥ √©s konkr√©t
- St√≠lus megjel√∂l√©ssel (pl. "professional photography", "digital illustration", "minimalist design")
- Sz√≠nek √©s hangulat megjel√∂l√©s√©vel
- Max 100 szavas"""
                    },
                    {
                        "role": "user",
                        "content": f"K√©sz√≠ts egy k√©pgener√°l√≥ promptot ehhez a poszthoz:\n\n{post_text}\n\nCsak a promptot √≠rd, semmi m√°st!"
                    }
                ],
                max_completion_tokens=1000  # GPT-5 uses reasoning tokens too, needs more space
            )

            prompt = response.choices[0].message.content.strip()
            print(f"‚úÖ Image prompt generated: {prompt[:50]}...")
            return prompt
        except Exception as e:
            print(f"‚ùå Error generating image prompt: {e}")
            return f"Professional social media visual representing: {post_text[:100]}"

    def generate_image(self, prompt: str) -> str:
        """
        Generate an image using DALL-E 3 (fallback)

        Args:
            prompt: Text description for image generation

        Returns:
            URL of the generated image
        """
        if not self.client:
            # Return a placeholder if no API key
            print("‚ö†Ô∏è OpenAI API not available, using placeholder image")
            return "https://images.unsplash.com/photo-1677442136019-21780ecad995?auto=format&fit=crop&q=80&w=1000"

        try:
            print(f"üé® Generating image with DALL-E 3 for: {prompt[:50]}...")
            response = self.client.images.generate(
                model="dall-e-3",
                prompt=f"Social media image for: {prompt}. High quality, professional, engaging style.",
                size="1024x1024",
                quality="standard",
                n=1,
            )
            image_url = response.data[0].url
            print(f"‚úÖ Image generated successfully")
            return image_url
        except Exception as e:
            print(f"‚ùå Image generation failed: {e}")
            # Error fallback
            return "https://images.unsplash.com/photo-1557683316-973673baf926?auto=format&fit=crop&w=1000"

    def generate_video(self, prompt: str, duration: int = 5) -> str:
        """
        Generate a video using OpenAI Sora 2

        Args:
            prompt: Text description for video generation
            duration: Video duration in seconds (4, 8, or 12)

        Returns:
            Path to the generated video file
        """
        if not self.client:
            print("‚ö†Ô∏è OpenAI API not available for video generation")
            return None

        try:
            import requests
            import tempfile
            import uuid
            import time

            print(f"üé¨ Generating video with Sora 2: {prompt[:50]}...")

            # Map duration to allowed values
            allowed_durations = {4: "4", 5: "4", 8: "8", 12: "12"}
            seconds_str = allowed_durations.get(duration, "4")
            if duration not in [4, 5, 8, 12]:
                print(f"‚ö†Ô∏è Duration {duration}s not allowed, using 4s instead")

            api_key = os.getenv('OPENAI_API_KEY')

            # Step 1: Create video generation job
            create_url = "https://api.openai.com/v1/videos"
            headers = {
                "Authorization": f"Bearer {api_key}"
            }

            # Use multipart/form-data as per API docs
            files = {
                'model': (None, 'sora-2'),
                'prompt': (None, f"Professional social media video: {prompt}"),
                'seconds': (None, seconds_str),
                'size': (None, '1280x720')
            }

            print(f"üì§ Creating video job...")
            create_response = requests.post(create_url, headers=headers, files=files)

            if create_response.status_code != 200:
                print(f"‚ùå Failed to create video job: {create_response.status_code}")
                print(f"Response: {create_response.text}")
                return None

            job_data = create_response.json()
            video_id = job_data.get('id')
            print(f"‚úÖ Video job created: {video_id}")
            print(f"   Status: {job_data.get('status')}")

            # Step 2: Poll job status until completed
            retrieve_url = f"https://api.openai.com/v1/videos/{video_id}"
            max_wait_time = 300  # 5 minutes max
            start_time = time.time()

            while time.time() - start_time < max_wait_time:
                time.sleep(5)  # Check every 5 seconds

                status_response = requests.get(retrieve_url, headers=headers)
                if status_response.status_code != 200:
                    print(f"‚ùå Failed to check status: {status_response.status_code}")
                    return None

                status_data = status_response.json()
                current_status = status_data.get('status')
                progress = status_data.get('progress', 0)

                print(f"‚è≥ Status: {current_status} ({progress}%)")

                if current_status == 'completed':
                    # Video is ready!
                    video_url = status_data.get('url')
                    if not video_url:
                        print("‚ùå No video URL in response")
                        return None

                    # Step 3: Download video
                    print(f"üì• Downloading video from: {video_url[:50]}...")

                    temp_dir = tempfile.gettempdir()
                    temp_filename = f"sora_{uuid.uuid4()}.mp4"
                    temp_path = os.path.join(temp_dir, temp_filename)

                    video_response = requests.get(video_url)
                    with open(temp_path, 'wb') as f:
                        f.write(video_response.content)

                    print(f"‚úÖ Video generated successfully with Sora 2")
                    return temp_path

                elif current_status == 'failed':
                    print(f"‚ùå Video generation failed")
                    return None

            print(f"‚ùå Video generation timed out after {max_wait_time}s")
            return None

        except Exception as e:
            print(f"‚ùå Sora video generation failed: {e}")
            import traceback
            traceback.print_exc()
            return None
